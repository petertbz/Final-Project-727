---
title: "Final-project-727"
author: "Group 8: Leng Seong Che, Bozhou (Peter) Tan"
date: "2023-11-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE) 
```

```{r}
library(appler)
library(tidyverse)
library(reshape2)
library(quanteda)
library(topicmodels)
library(tidyverse)
library(knitr)
library(plotly)
library(pals)
```

```{r}
# build the list of browsers
browser = data.frame(name = c("safari", "edge", "chrome", "firefox", "opera"),
                     fullname = c("Safari", "Microsoft Edge", "Google Chrome",
                                     "Mozilla Firefox","Opera Browser"))
```

```{r}
# build a function to acquire the app id from the Apple API
getid = function(name){
  id = search_apple(name, media = "software", entity = "software")[1,]
  trackId = id$trackId
  return(trackId)
}
```

```{r}
# extract appid from the Apple API
browser$id = sapply(browser$fullname, getid)

# acquire the reviews of each browser
for (i in 1:dim(browser)[1]) {
  name = browser$name[i]
  review = get_apple_reviews(browser$id[i], country = "us", 
                    all_results = TRUE, sort_by = "mosthelpful")
  assign(name, review)
}

```


```{r}
# get ratings of each browser
ratings = data.frame(browser = c("chrome", "edge", "firefox", "safari", "opera"), 
                     rating = c(mean(chrome$rating), mean(edge$rating), mean(firefox$rating), mean(safari$rating), mean(opera$rating)),
                     n_positive = c(sum(chrome$rating >= 3), sum(edge$rating >= 3), sum(firefox$rating >= 3), sum(safari$rating >= 3), sum(opera$rating >= 3)),
                     n_negative = c(sum(chrome$rating < 3), sum(edge$rating < 3), sum(firefox$rating < 3), sum(safari$rating < 3),  sum(opera$rating < 3)))
kable(ratings, caption = "ratings")

# Create interactive plot, may not be necessary...static plot or a table should be clear enough
plot_ly(ratings, x = ~browser, y = ~rating, mode = 'markers')
```

Opera has the highest rating (4.006) by users among the five browsers, followed by edge, firefox, safari, and chrome.

## Top 15 Topics for Reviews by Browser

```{r}
# combine all datasets
chrome = chrome %>% mutate(browser = "chrome")
edge = edge %>% mutate(browser = "edge")
safari = safari %>% mutate(browser = "safari")
opera = opera %>% mutate(browser = "opera")
firefox = firefox %>% mutate(browser = "firefox")

pattern = "edge|chrome|safari|firefox|opera|browser|google|microsoft|mozilla|apple|app|apps|bing|â€™"

df = rbind(chrome, edge, safari, opera, firefox)
df$review = tolower(df$review) 
df$review = gsub(pattern, "", df$review, ignore.case = TRUE)

# topicmodels 
corpus_df = corpus(df$review)
```

```{r}
# topicmodels 
corpus_df = corpus(df$review)

# Tokenization
corpus_df_proc = tokens(corpus_df, 
                            remove_punct = TRUE, # remove punctuation
                            remove_numbers = TRUE, # remove numbers
                            remove_symbols = TRUE) %>% # remove symbols (for social media data, could remove everything except letters)
  tokens_tolower() # remove capitalization
```


```{r}
# Lemmatization #
lemmaData = read.csv2("baseform_en.tsv", 
                      sep="\t", 
                      header=FALSE, 
                      encoding = "UTF-8", 
                      stringsAsFactors = F) %>% 
  na.omit()

# "Substitute token types based on vectorized one-to-one matching"
corpus_df_proc = tokens_replace(corpus_df_proc, 
                                    lemmaData$V1, 
                                    lemmaData$V2,
                                    valuetype = "fixed") 

stop = stopwords("english", source = "stopwords-iso")
# remove stopwords
corpus_df_proc = corpus_df_proc %>%
  tokens_remove(stop) %>%
  tokens_ngrams(1) 
```


```{r}
#  Create dtm
DTM = dfm(corpus_df_proc)

# Minimum
minimumFrequency = 10
DTM = dfm_trim(DTM, 
               min_docfreq = minimumFrequency,
               max_docfreq = 100000)

# keep only letters... brute force
DTM  = dfm_select(DTM, 
                  pattern = "[a-z]", 
                  valuetype = "regex", 
                  selection = 'keep')
colnames(DTM) = stringi::stri_replace_all_regex(colnames(DTM), 
                                                "[^_a-z]","")

DTM = dfm_compress(DTM, "features")

```

```{r}
K = 10
# Set seed to make results reproducible
set.seed(9161)
topicModel = LDA(DTM, 
                 K, 
                 method="Gibbs", 
                 control=list(iter = 500, 
                              verbose = 25))

tmResult = posterior(topicModel)
```


```{r}
# Topics are distributions over the entire vocabulary

beta = tmResult$terms
#glimpse(beta)            

# Each doc has a distribution over k topics

theta = tmResult$topics
#glimpse(theta)               

terms(topicModel, 10)

# Top terms per topic. Use top 5 to interpret topics
top5termsPerTopic = terms(topicModel, 5)

# give the topics more descriptive names than just numbers, concatenate the five most likely terms of each topic to a string that represents a pseudo-name for each topic.
topicNames = apply(top5termsPerTopic, 
                   2, 
                   paste, 
                   collapse=" ")

topicProportions = colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) = topicNames     # Topic Names
sort(topicProportions, decreasing = TRUE) # sort

```

```{r}
# What was the value in the previous model?
attr(topicModel, "alpha") 

# Re-estimate model with alpha set by us, keep either topicModel or topicModel2
topicModel2 = LDA(DTM, 
                  K, 
                  method="Gibbs", 
                  control=list(iter = 500, 
                               verbose = 25, 
                               alpha = 0.2))
tmResult = posterior(topicModel2)
theta = tmResult$topics
beta = tmResult$terms


topicProportions = colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) = topicNames     # Topic Names 
sort(topicProportions, decreasing = TRUE) # sort

topicNames = apply(terms(topicModel2, 5), 2, paste, collapse = " ")  # top five terms per topic 
```


```{r}
# Average theme proportions by browser
topic_proportion_per_decade = aggregate(theta, 
                                        by = list(browser = df$browser), 
                                        mean)
colnames(topic_proportion_per_decade)[2:(K+1)] = topicNames
vizDataFrame1 = melt(topic_proportion_per_decade, 
                     id.vars = "browser")

if(!require(pals)) install.packages("pals")
library(pals)
ggplot(vizDataFrame1, 
       aes(x=browser, 
           y=value, 
           fill=variable)) + 
  geom_bar(stat = "identity")+
  labs(title = "Top 10 Topics for App Store Reviews by Browser", 
       y = "proportion") +
  scale_fill_manual(values = paste0(alphabet(20), "FF"), name = "Topics")
```

## Top 10 Topics for Positive Reviews (Rating >= 3) by Browser

```{r}
df1 = rbind(chrome, edge, safari, opera, firefox) %>% filter(rating >= 3)
df1$review = tolower(df1$review) 
df1$review = gsub(pattern, "", df1$review, ignore.case = TRUE, perl = TRUE)

# topicmodels 
corpus_df1 = corpus(df1$review)
```

```{r}
# Tokenization
corpus_df1_proc = tokens(corpus_df1, 
                        remove_punct = TRUE, # remove punctuation
                        remove_numbers = TRUE, # remove numbers
                        remove_symbols = TRUE) %>% # remove symbols (for social media data, could remove everything except letters)
  tokens_tolower() # remove capitalization
```

```{r}
# Lemmatization #
lemmaData = read.csv2("baseform_en.tsv", 
                      sep="\t", 
                      header=FALSE, 
                      encoding = "UTF-8", 
                      stringsAsFactors = F) %>% 
  na.omit()
```

```{r}
# "Substitute token types based on vectorized one-to-one matching"
corpus_df1_proc = tokens_replace(corpus_df1_proc, 
                                lemmaData$V1, 
                                lemmaData$V2,
                                valuetype = "fixed") 

```

```{r}
# remove stopwords
corpus_df1_proc = corpus_df1_proc %>%
  tokens_remove(stop) %>%
  tokens_ngrams(1) 

```


```{r}
#  Create dtm
DTM = dfm(corpus_df1_proc)

# Minimum
minimumFrequency = 10
DTM = dfm_trim(DTM, 
               min_docfreq = minimumFrequency,
               max_docfreq = 100000)

# keep only letters... brute force
DTM  = dfm_select(DTM, 
                  pattern = "[a-z]", 
                  valuetype = "regex", 
                  selection = 'keep')
colnames(DTM) = stringi::stri_replace_all_regex(colnames(DTM), 
                                                "[^_a-z]","")

DTM = dfm_compress(DTM, "features")

```

```{r}
K = 10
# Set seed to make results reproducible
set.seed(9161)
topicModel = LDA(DTM, 
                 K, 
                 method="Gibbs", 
                 control=list(iter = 500, 
                              verbose = 25))

tmResult = posterior(topicModel)

```

```{r}
# Topics are distributions over the entire vocabulary

beta = tmResult$terms
#glimpse(beta)            

# Each doc has a distribution over k topics

theta = tmResult$topics
#glimpse(theta)               

terms(topicModel, 10)

# Top terms per topic. Use top 5 to interpret topics
top5termsPerTopic = terms(topicModel, 5)

# give the topics more descriptive names than just numbers, concatenate the five most likely terms of each topic to a string that represents a pseudo-name for each topic.
topicNames = apply(top5termsPerTopic, 
                   2, 
                   paste, 
                   collapse=" ")

topicProportions = colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) = topicNames     # Topic Names
sort(topicProportions, decreasing = TRUE) # sort

```

```{r}
# What was the value in the previous model?
attr(topicModel, "alpha") 

# Re-estimate model with alpha set by us, keep either topicModel or topicModel2
topicModel2 = LDA(DTM, 
                  K, 
                  method="Gibbs", 
                  control=list(iter = 500, 
                               verbose = 25, 
                               alpha = 0.2))
tmResult = posterior(topicModel2)
theta = tmResult$topics
beta = tmResult$terms


topicProportions = colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) = topicNames     # Topic Names 
sort(topicProportions, decreasing = TRUE) # sort

topicNames = apply(terms(topicModel2, 5), 2, paste, collapse = " ")  # top five terms per topic 

```

```{r}
# Average theme proportions by decade
topic_proportion_per_decade = aggregate(theta, 
                                        by = list(browser = df1$browser), 
                                        mean)
colnames(topic_proportion_per_decade)[2:(K+1)] = topicNames
vizDataFrame2 = melt(topic_proportion_per_decade, 
                    id.vars = "browser")

ggplot(vizDataFrame2, 
       aes(x=browser, 
           y=value, 
           fill=variable)) + 
  geom_bar(stat = "identity")+
  labs(title = "Top 10 Topics for Positive App Store Reviews by Browser", 
      y = "proportion") +
  scale_fill_manual(values = paste0(alphabet(20), "FF"), name = "Topics")

```

## Top 10 Negative Reviews (rating < 3) by Browser

```{r}
df2 = rbind(chrome, edge, safari, opera, firefox) %>% filter(rating < 3)
df2$review = tolower(df2$review) 
df2$review = gsub(pattern, "", df2$review, ignore.case = TRUE, perl = TRUE)

# topicmodels 
corpus_df2 = corpus(df2$review)
```

```{r}
# Tokenization
corpus_df2_proc = tokens(corpus_df2, 
                         remove_punct = TRUE, # remove punctuation
                         remove_numbers = TRUE, # remove numbers
                         remove_symbols = TRUE) %>% # remove symbols (for social media data, could remove everything except letters)
  tokens_tolower() # remove capitalization
```

```{r}
# Lemmatization #
lemmaData = read.csv2("baseform_en.tsv", 
                      sep="\t", 
                      header=FALSE, 
                      encoding = "UTF-8", 
                      stringsAsFactors = F) %>% 
  na.omit()

```

```{r}
# "Substitute token types based on vectorized one-to-one matching"
corpus_df2_proc = tokens_replace(corpus_df2_proc, 
                                 lemmaData$V1, 
                                 lemmaData$V2,
                                 valuetype = "fixed") 

```

```{r}
# remove stopwords
corpus_df2_proc = corpus_df2_proc %>%
  tokens_remove(stop) %>%
  tokens_ngrams(1) 

```

```{r}
#  Create dtm
DTM = dfm(corpus_df2_proc)

# Minimum
minimumFrequency = 10
DTM = dfm_trim(DTM, 
               min_docfreq = minimumFrequency,
               max_docfreq = 100000)

# keep only letters... brute force
DTM  = dfm_select(DTM, 
                  pattern = "[a-z]", 
                  valuetype = "regex", 
                  selection = 'keep')
colnames(DTM) = stringi::stri_replace_all_regex(colnames(DTM), 
                                                "[^_a-z]","")

DTM = dfm_compress(DTM, "features")
```

```{r}
K = 10
# Set seed to make results reproducible
set.seed(9161)
topicModel = LDA(DTM, 
                 K, 
                 method="Gibbs", 
                 control=list(iter = 500, 
                              verbose = 25))

tmResult = posterior(topicModel)

# Topics are distributions over the entire vocabulary

beta = tmResult$terms
#glimpse(beta)            

# Each doc has a distribution over k topics

theta = tmResult$topics
#glimpse(theta)               

terms(topicModel, 10)

# Top terms per topic. Use top 5 to interpret topics
top5termsPerTopic = terms(topicModel, 5)

# give the topics more descriptive names than just numbers, concatenate the five most likely terms of each topic to a string that represents a pseudo-name for each topic.
topicNames = apply(top5termsPerTopic, 
                   2, 
                   paste, 
                   collapse=" ")

topicProportions = colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) = topicNames     # Topic Names
sort(topicProportions, decreasing = TRUE) # sort
```

```{r}
# What was the value in the previous model?
attr(topicModel, "alpha") 

# Re-estimate model with alpha set by us, keep either topicModel or topicModel2
topicModel2 = LDA(DTM, 
                  K, 
                  method="Gibbs", 
                  control=list(iter = 500, 
                               verbose = 25, 
                               alpha = 0.2))
tmResult = posterior(topicModel2)
theta = tmResult$topics
beta = tmResult$terms


topicProportions = colSums(theta) / nrow(DTM)  # average probability over all paragraphs
names(topicProportions) = topicNames     # Topic Names 
sort(topicProportions, decreasing = TRUE) # sort

topicNames = apply(terms(topicModel2, 5), 2, paste, collapse = " ")  # top five terms per topic 

```

```{r}
# Average theme proportions by browser
topic_proportion_per_decade = aggregate(theta, 
                                        by = list(browser = df2$browser), 
                                        mean)
colnames(topic_proportion_per_decade)[2:(K+1)] = topicNames
vizDataFrame3 = melt(topic_proportion_per_decade, 
                    id.vars = "browser")

if(!require(pals)) install.packages("pals")
library(pals)
ggplot(vizDataFrame3, 
       aes(x=browser, 
           y=value, 
           fill=variable)) + 
  geom_bar(stat = "identity")+
  labs(title = "Top 10 Topics for Negative App Store Reviews by Browser", 
       y = "proportion") +
  scale_fill_manual(values = paste0(alphabet(20), "FF"), name = "Topics") 
```

```{r}
save(vizDataFrame1, vizDataFrame2, vizDataFrame3, ratings, file = "results.RData")
```